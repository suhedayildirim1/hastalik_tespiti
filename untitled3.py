# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ayh4we2keDN-4mHp3zmY03Jsqgx-RICL
"""

#Drive a bağlanan blok
from google.colab import drive
drive.mount('/content/drive')

# import os
# belirtilen dizinin altında hangi klasörler veya dosyalar var onu gösteren kod(kontrol amaçlı kullanılıyor.)
# folder_path = "/content/drive/MyDrive/split_dataset/train"
# print(os.listdir(folder_path))

# zip_path = '/content/drive/MyDrive/COVID-19_Radiography_Dataset.zip'

# import zipfile

# # Zip dosyasını açma
# with zipfile.ZipFile(zip_path, 'r') as zip_ref:
#     zip_ref.extractall('/content/drive/MyDrive/COVID-19_Radiography_Dataset')

# import os

# # Veri setinin yolunu belirleme
# dataset_path = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'

# # Veri setinin içeriğini listeleme
# print("Veri seti içeriği:", os.listdir(dataset_path))

# !pip install split-folders

# import splitfolders

# # Veri setinin bulunduğu dizin
# input_folder = "/content/drive/MyDrive/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset"
# # Çıktı dizini (train ve test klasörleri buraya kaydedilecek)
# output_folder = "/content/drive/MyDrive/split_dataset"

# # Veri setini ayırma ( %80 train, %20 test)
# splitfolders.ratio(
#     input=input_folder,
#     output=output_folder,
#     seed=42,  # Rastgelelik için
#     ratio=(0.8, 0.2),  # Train ve test oranı
#     group_prefix=None,  # Gruplama yapmak için kullanılır
#     move=False  # Dosyaları kopyalar, orijinal dosyaları silmez
# )

# print("Veri seti başarıyla ayrıldı!")

# import splitfolders

# # Sadece train klasöründen val çıkartmak için
# train_folder = "/content/drive/MyDrive/split_dataset/train"
# new_output_folder = "/content/drive/MyDrive/split_dataset/validation"

# splitfolders.ratio(
#     input=train_folder,
#     output=new_output_folder,
#     seed=42,
#     ratio=(0.8, 0.2),  # yeni train ve val oranı
#     move=False  # Kopyalama yapılır, dosyalar silinmez
# )

# import os
# #data ayrıldı mı ayrıldıysa altındaki klasörleri görüyoruz
# folder_path = "/content/drive/MyDrive/split_dataset/validation"
# print(os.listdir(folder_path))
# print("Dosya var mı?", os.path.exists(folder_path))

# #düzgün ayrılıp ayrılmadığını kontrol ettiğimiz blok
# output_folder = "/content/drive/MyDrive/split_dataset"

# # Train ve test klasörlerini listeleme
# train_folder = os.path.join(output_folder, "train")
# test_folder = os.path.join(output_folder, "test")

# print("Train klasörü içeriği:")
# for class_name in os.listdir(train_folder):
#     class_path = os.path.join(train_folder, class_name)
#     print(f"{class_name}: {len(os.listdir(class_path))} dosya")

# print("\nTest klasörü içeriği:")
# for class_name in os.listdir(test_folder):
#     class_path = os.path.join(test_folder, class_name)
#     print(f"{class_name}: {len(os.listdir(class_path))} dosya")



"""

import tensorflow as tf
print("GPU aktif mi?", tf.config.list_physical_devices('GPU'))
!nvidia-smi

#gerekli kütüphaneleri yükleme işlemi
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

#  GPU AYARLARI
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)
    BATCH_SIZE = 64
    print("GPU AKTİF:", gpus[0])
else:
    BATCH_SIZE = 64
    print("GPU YOK, CPU KULLANILIYOR")

# DRIVE BAĞLANTISI
from google.colab import drive
drive.mount('/content/drive')

# Eğitim veri seti için veri artırma
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
# Test veri seti için sadece ölçeklendirme //veri artırma testte uygulanmaz.model performansını gerçekçi şekilde ölçmek için.
test_datagen = ImageDataGenerator(rescale=1./255)

train_path = '/content/drive/MyDrive/split_dataset/validation/train'
val_path = '/content/drive/MyDrive/split_dataset/validation/val'
test_path = '/content/drive/MyDrive/veri/split_dataset/test'

import os

# Drive'ın bağlı olup olmadığını kontrol et
if os.path.exists('/content/drive'):
    print("Google Drive zaten bağlı.")
else:
    print("Google Drive bağlı değil. Lütfen bağlayın.")

# EĞİTİM VERİ YÜKLEYİCİ
train_generator = train_datagen.flow_from_directory(
    directory='/content/drive/MyDrive/split_dataset/validation/train',
    target_size=(224, 224),
    batch_size=64,
    class_mode='categorical'
)

#Val
val_generator = train_datagen.flow_from_directory(
    directory='/content/drive/MyDrive/split_dataset/validation/val',
    target_size=(224, 224),
    batch_size=64,
    class_mode='categorical'
)

# TEST VERİ YÜKLEYİCİ
test_generator = test_datagen.flow_from_directory(
    directory='/content/drive/MyDrive/split_dataset/test',
    target_size=(224, 224),
    batch_size=64,
    class_mode='categorical',
    shuffle = False
)

from tensorflow.keras.applications import DenseNet121, ResNet152V2, DenseNet201,DenseNet169, MobileNetV2, VGG19, VGG16
base_model =  DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
from tensorflow.keras.layers import Dropout, BatchNormalization
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(4096, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(2048, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)

for layer in base_model.layers:
    layer.trainable = TrueA
model = Model(inputs=base_model.input, outputs=predictions)


from tensorflow.keras.applications import DenseNet121, ResNet152V2, DenseNet201,DenseNet169, MobileNetV2, VGG19, VGG16
base_model =  ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Modelin çıktısını alma işlemi
from tensorflow.keras.layers import Dropout, BatchNormalization
x = base_model.output
x = GlobalAveragePooling2D()(x)

x = Dense(4096, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(2048, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)


predictions = Dense(train_generator.num_classes, activation='softmax')(x)
for layer in base_model.layers:
    layer.trainable = True

# Modeli oluştur
model_resnet = Model(inputs=base_model.input, outputs=predictions)


from tensorflow.keras.applications import DenseNet121, ResNet152V2, DenseNet201,DenseNet169, MobileNetV2, VGG19, VGG16
base_model =  MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Modelin çıktısını alma işlemi
from tensorflow.keras.layers import Dropout, BatchNormalization
x = base_model.output
x = GlobalAveragePooling2D()(x)

x = Dense(4096, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(2048, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)


predictions = Dense(train_generator.num_classes, activation='softmax')(x)
for layer in base_model.layers:
    layer.trainable = True

# Modeli oluştur
model_mobilenet = Model(inputs=base_model.input, outputs=predictions)

# from tensorflow.keras.applications import DenseNet201, MobileNetV2, ResNet152V2
# from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Concatenate, Input
# from tensorflow.keras.models import Model
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# # Base modeller + isim verme
# base_model1 = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# base_model1._name = 'DenseNet201'

# base_model2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# base_model2._name = 'MobileNetV2'

# base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# base_model3._name = 'ResNet152V2'

# # Ortak input (bir tanesinin inputunu kullanıyoruz — DenseNet201)
# input_tensor = base_model1.input

# # Feature extraction
# x1 = base_model1.output
# x1 = GlobalAveragePooling2D()(x1)

# x2 = base_model2(input_tensor)
# x2 = GlobalAveragePooling2D()(x2)

# x3 = base_model3(input_tensor)
# x3 = GlobalAveragePooling2D()(x3)

# # Concatenate
# combined = Concatenate()([x1, x2, x3])

# # Üst katmanlar
# x = Dense(4096, activation='relu')(combined)
# x = Dropout(0.4)(x)
# x = Dense(2048, activation='relu')(x)
# x = Dropout(0.4)(x)
# x = Dense(1024, activation='relu')(x)
# x = Dropout(0.4)(x)
# x = Dense(512, activation='relu')(x)
# x = Dropout(0.4)(x)

# # Output
# predictions = Dense(train_generator.num_classes, activation='softmax')(x)

# # Model oluştur
# ensemble_model = Model(inputs=input_tensor, outputs=predictions)

# # Layer'ları trainable yap
# for layer in base_model1.layers:
#     layer.trainable = True
# for layer in base_model2.layers:
#     layer.trainable = True
# for layer in base_model3.layers:
#     layer.trainable = True

# # Compile
# ensemble_model.compile(optimizer=Adam(learning_rate=0.001),
#                        loss='categorical_crossentropy',
#                        metrics=['accuracy'])
# reduce_lr = ReduceLROnPlateau(
#     monitor='val_loss',
#     factor=0.3,
#     patience=3,
#     verbose=1,
#     min_lr=1e-6
# )

# callbacks = [reduce_lr]

# # Model eğitimi
# history = ensemble_model.fit(
#     train_generator,
#     epochs=30,
#     validation_data=val_generator,
#     callbacks=callbacks
# )

model_resnet.load_weights('/content/drive/MyDrive/model_kayitlarim/resnet152v2_model.h5',
                         by_name=True, skip_mismatch=True)

model_densenet.load_weights('/content/drive/MyDrive/model_kayitlarim/DenseNet201_model.h5')

model_mobilenet.load_weights('/content/drive/MyDrive/model_kayitlarim/MobileNetV2_model.h5')

# Test verisini numpy array olarak alalım
# Gerçek test için: x_test, y_test = test_generator.next() veya .predict(x)

# Her modelin softmax çıktısı
pred1 = model_densenet.predict(test_generator, verbose=1)
pred2 = model_resnet.predict(test_generator, verbose = 1)
pred3 = model_mobilenet.predict(test_generator, verbose = 1)

import numpy as np

y_pred_soft = np.argmax((pred1 + pred2 + pred3) / 3, axis=1)

y_true = test_generator.classes

# Hard ensemble: her modelin sınıf tahmini alınır
vote1 = np.argmax(pred1, axis=1)
vote2 = np.argmax(pred2, axis=1)
vote3 = np.argmax(pred3, axis=1)

from scipy.stats import mode
votes = np.stack([vote1, vote2, vote3], axis=0)
y_pred_hard, _ = mode(votes, axis=0)
y_pred_hard = y_pred_hard.flatten()

from sklearn.metrics import classification_report

true_labels = test_generator.classes
print("Soft Voting Report:")

class_labels = list(test_generator.class_indices.keys())

report = classification_report(true_labels, y_pred_soft, target_names=class_labels)
print(report)

with open("/content/drive/MyDrive/model_kayitlarim/y_pred_soft_classification_report.txt", "w") as file:
    file.write(report)

print("Hard Voting Report:")

report = classification_report(true_labels, y_pred_hard, target_names=class_labels)
with open("/content/drive/MyDrive/model_kayitlarim/y_pred_hard_classification_report.txt", "w") as file:
    file.write(report)

print(report)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Ensemble tahmin çıktılarını kullanalım
# Örn: soft voting sonucu
preds_classes = y_pred_soft  # veya y_pred_hard

# 2. Gerçek değerleri al
y_true = test_generator.classes  # genelde one-hot değil, class index olur

# 3. Confusion matrix hesapla
cm = confusion_matrix(y_true, preds_classes)

# 4. Görselleştirme
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

# Sınıf isimleri — test_generator.class_indices sırasını baz alabiliriz
sınıf_isimleri = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']

plt.xticks(np.arange(len(sınıf_isimleri)) + 0.5, sınıf_isimleri)
plt.yticks(np.arange(len(sınıf_isimleri)) + 0.5, sınıf_isimleri, rotation=0)
plt.ylabel('Gerçek Değerler')
plt.xlabel('Tahmin Edilenler')
plt.title('Ensemble Confusion Matrix')
plt.savefig('/content/drive/MyDrive/model_kayitlarim/ensemble_conf_matrix.png')

plt.show()

from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# Ensemble sonucunu kullan
preds_classes = y_pred_soft  # veya y_pred_hard

# Gerçek sınıflar
true_classes = test_generator.classes

# Sınıf isimleri
class_labels = list(test_generator.class_indices.keys())

# Rapor oluştur
report = classification_report(true_classes, preds_classes, target_names=class_labels)
print(report)

# Raporu dosyaya kaydet
with open("/content/drive/MyDrive/model_kayitlarim/ensemble_classification_report.txt", "w") as file:
    file.write(report)

# model.compile(optimizer=Adam(learning_rate=0.001),  # Optimizasyon algoritması
#         loss='categorical_crossentropy',  # Kayıp fonksiyonu
#          metrics=['accuracy'])

# train_generator.samples // train_generator.batch_size

# print(tf.__version__)

# tf.config.list_physical_devices('GPU')

# # GPU'nun gerçekten kullanılıp kullanılmadığını test etme
# with tf.device('/GPU:0'):
#     a = tf.constant([1.0, 2.0], shape=(2, 1))
#     b = tf.constant([3.0, 4.0], shape=(1, 2))
#     c = tf.matmul(a, b)
#     print(c)

# from tensorflow.keras.callbacks import ReduceLROnPlateau

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1,
    min_lr=1e-7
)

# # #  MODEL DERLEME
# # model.compile(
# #     optimizer='adam',
# #     loss='categorical_crossentropy',
# #     metrics=['accuracy']
# # )

#  EĞİTİM
with tf.device('/GPU:0'):
  history = model.fit(
      train_generator,
      validation_data=val_generator,
      epochs=100,
      verbose=1,
      callbacks=[lr_scheduler]
  )

#çalıştırmadan önce hangi modeli kaydedeceksem adını değiştireceğim.
model.save('/content/drive/MyDrive/model_kayitlarim/DenseNet201_model.h5')

# Class index → Class name eşleme (bunu 1 kere yukarıya koyarsam, hepsi için geçerli)
class_indices = train_generator.class_indices
index_to_class = {v: k for k, v in class_indices.items()}

!pip install tf-keras-vis tensorflow

import os
import random
import numpy as np
import tensorflow as tf

# Sabit tohumlar
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# GPU deterministik çalışsın
os.environ['TF_DETERMINISTIC_OPS'] = '1'

import numpy as np
import matplotlib.pyplot as plt
from tf_keras_vis.gradcam import Gradcam
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear
from tf_keras_vis.utils.scores import CategoricalScore
import cv2

# Class index to class name map
class_indices = train_generator.class_indices
index_to_class = {v: k for k, v in class_indices.items()}

# Test batch al
X_test_batch, y_test_batch = next(test_generator)

# Örnek resim
target_image = X_test_batch[0:1]  # (1, 224, 224, 3)

# Grad-CAM
gradcam = Gradcam(model_densenet, model_modifier=ReplaceToLinear())

num_classes = model_densenet.output.shape[-1]

# Görselleştirme
plt.figure(figsize=(4 * num_classes, 4))

for class_idx in range(num_classes):
    score = CategoricalScore([class_idx])
    cam = gradcam(score, target_image, training  = False)
    heatmap = cam[0]

    # Görüntüyü yeniden ölçekle
    heatmap_resized = cv2.resize(heatmap, (target_image.shape[2], target_image.shape[1]))
    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(cv2.cvtColor((target_image[0] * 255).astype(np.uint8), cv2.COLOR_RGB2BGR), 1,
                              heatmap_colored, 0.4, 0)

    # RGB gösterim için
    overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)

    # Plot
    plt.subplot(1, num_classes, class_idx + 1)
    plt.imshow(overlay_rgb)
    plt.title(f'Class: {index_to_class[class_idx]}')
    plt.axis('off')

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/model_kayitlarim/Dense/Gradcam.png')
plt.show()

# Yükleme
!pip install tf-explain

# İmport
from tf_explain.core.integrated_gradients import IntegratedGradients
import matplotlib.pyplot as plt

# Test batch al
X_test_batch, y_test_batch = next(test_generator)
target_image = X_test_batch[0:1]

num_classes = model.output.shape[-1]

# Plot
plt.figure(figsize=(4 * num_classes, 4))

for class_idx in range(num_classes):
    # Integrated Gradients nesnesi
    explainer = IntegratedGradients()

    # IG hesapla
    grid = explainer.explain(validation_data=(target_image, np.array([class_idx])),
                             model=model,
                             class_index=class_idx)

    # Plot
    plt.subplot(1, num_classes, class_idx + 1)
    plt.imshow(grid)

    class_name = index_to_class[class_idx]
    plt.title(f'Class: {class_name}')
    plt.axis('off')

plt.savefig('/content/drive/MyDrive/model_kayitlarim/Dense/IntegratedGradients.png')

plt.tight_layout()
plt.show()

# Yükleme
!pip install lime scikit-image

# İmportlar
from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

# Test batch al
X_test_batch, y_test_batch = next(test_generator)
target_image = X_test_batch[0]  # LIME tek resim alıyor, (H,W,C)

num_classes = model.output.shape[-1]

# LIME objesi
explainer = lime_image.LimeImageExplainer()

# Plot
plt.figure(figsize=(4 * num_classes, 4))

for class_idx in range(num_classes):
    # LIME explanation
    explanation = explainer.explain_instance(image=target_image.astype('double'),
                                             classifier_fn=model.predict,
                                             top_labels=num_classes,
                                             hide_color=0,
                                             num_samples=1000)

    # Görselleştir
    temp, mask = explanation.get_image_and_mask(class_idx, positive_only=True, hide_rest=False)

    plt.subplot(1, num_classes, class_idx + 1)
    plt.imshow(mark_boundaries(temp / 255.0, mask))

    class_name = index_to_class[class_idx]
    plt.title(f'Class: {class_name}')
    plt.axis('off')


plt.savefig('/content/drive/MyDrive/model_kayitlarim/Dense/lime_image.png')

plt.tight_layout()
plt.show()

# Yükleme
!pip install tf-explain

# İmport
from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity
import matplotlib.pyplot as plt

# Test batch al
X_test_batch, y_test_batch = next(test_generator)
target_image = X_test_batch[0:1]

num_classes = model_densenet.output.shape[-1]

# Plot
plt.figure(figsize=(4 * num_classes, 4))

for class_idx in range(num_classes):
    # OcclusionSensitivity nesnesi
    explainer = OcclusionSensitivity()

    # Sensitivity hesapla → burada patch_size ekledim!
    grid = explainer.explain(validation_data=(target_image, np.array([class_idx])),
                             model=model_densenet,
                             class_index=class_idx,
                             patch_size=20)   # <<< burayı ekledim

    # Plot
    plt.subplot(1, num_classes, class_idx + 1)
    plt.imshow(grid)

    class_name = index_to_class[class_idx]
    plt.title(f'Class: {class_name}')
    plt.axis('off')

plt.savefig('/content/drive/MyDrive/model_kayitlarim/Dense/OcclusionSensitivity.png')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train vs Validation Loss')
plt.legend()
plt.grid(True)
plt.savefig('/content/drive/MyDrive/model_kayitlarim/DenseNet201_model_loss.png')
plt.show()

plt.figure(figsize=(10, 5))

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Train vs Validation Accuracy')
plt.legend()
plt.grid(True)
plt.savefig('/content/drive/MyDrive/model_kayitlarim/DenseNet201_acc.png')
plt.show()

from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# Test verilerini kullanarak tahmin yapma
preds = ensemble_model.predict(test_generator)
preds_classes = np.argmax(preds, axis=1)

true_classes = test_generator.classes

class_labels = list(test_generator.class_indices.keys())

report = classification_report(true_classes, preds_classes, target_names=class_labels)
print(report)

with open("/content/drive/MyDrive/model_kayitlarim/DenseNet201_classification_report.txt", "w") as file:
    file.write(report)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np


# 2. Gerçek değerleri hazırlama
y_true = test_generator.classes

# 3. Confusion matrix hesaplama
cm = confusion_matrix(y_true, preds_classes)

# 4. Görselleştirme
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

# Sınıf isimleri
sınıf_isimleri = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']

plt.xticks(np.arange(4)+0.5, sınıf_isimleri)
plt.yticks(np.arange(4)+0.5, sınıf_isimleri, rotation=0)
plt.ylabel('Gerçek Değerler')
plt.xlabel('Tahmin Edilenler')
plt.title('Confusion Matrix')
plt.savefig('/content/drive/MyDrive/model_kayitlarim/DenseNet201_model_confs_matrix.png')

plt.show()

# from PIL import Image
# import os

# def check_images(directory):
#     corrupted = []
#     for root, _, files in os.walk(directory):
#         for file in files:
#             if file.lower().endswith(('.png', '.jpg', '.jpeg')):
#                 try:
#                     img_path = os.path.join(root, file)
#                     Image.open(img_path).verify()
#                 except Exception as e:
#                     corrupted.append(img_path)
#                     print(f"❌ Bozuk dosya: {img_path} | Hata: {str(e)}")
#     return corrupted

# # Tüm veri setini kontrol et
# corrupted_files_test = check_images("/content/drive/MyDrive/split_dataset/test")
# corrupted_files_train = check_images("/content/drive/MyDrive/split_dataset/train")
# print(f"\nToplam bozuk dosya test: {len(corrupted_files_test)}")
# print(f"\nToplam bozuk dosya train: {len(corrupted_files_train)}")

